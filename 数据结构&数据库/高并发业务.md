当业务量达到“巨大”级别（如亿级数据、高并发读写），数据库设计需从**架构分层**、**分库分表**、**存储优化**、**高可用**等维度系统性规划，避免单库单表瓶颈。以下是完整的设计方案：


### 一、先做“架构分层”：分流数据库压力
业务量巨大时，**单一数据库无法承载所有压力**，需通过分层架构拆分流量和数据：

#### 1. 数据分层存储
| 分层         | 用途                          | 存储选型                          |
|--------------|-------------------------------|-----------------------------------|
| 核心业务库   | 订单、支付、用户核心数据（高并发读写） | MySQL（InnoDB）                   |
| 非核心业务库 | 商品详情、日志、评论（读多写少）     | MySQL/PostgreSQL                  |
| 数据仓库     | 报表统计、数据分析（离线查询）       | ClickHouse/Spark/Hive             |
| 缓存层       | 热点数据（如商品库存、用户信息）     | Redis/Memcached                   |
| 搜索引擎     | 全文检索（如商品搜索）              | Elasticsearch                     |

**作用**：将高频读写、低频查询、全文检索分流到不同存储，避免核心库被“拖垮”。


#### 2. 读写分离（解决读压力）
核心业务库采用**“主库写 + 从库读”**架构：
- **主库**：处理写操作（插入/更新/删除）和核心读操作；
- **从库**：通过主从复制同步数据，处理普通查询、报表查询；
- **扩展**：可部署多从库（如1主3从），通过中间件（如ProxySQL）做读负载均衡。

**注意**：主从复制存在延迟（毫秒级~秒级），对实时性要求高的场景需做特殊处理（如强制读主库）。


### 二、分库分表：突破单库单表极限
当单库数据量超过1000万、QPS超过1万时，需通过**分库分表**拆分数据：

#### 1. 分库策略：先按“业务模块”垂直分库
- **原则**：将不同业务模块的数据拆分到独立数据库，降低单库负载。
  示例：
  - 用户库（user_db）：存储用户信息、登录凭证；
  - 订单库（order_db）：存储订单、支付记录；
  - 商品库（product_db）：存储商品、库存、类目。
- **进阶**：若某模块数据量仍过大（如订单库），再做**水平分库**（按分片键拆分到多个订单库）。

#### 2. 分表策略：水平分表（核心）
分表需选对**分片键**（拆分依据），结合业务场景选择：

| 分片策略         | 分片键          | 适用场景                          | 优点                              | 缺点                              |
|------------------|-----------------|-----------------------------------|-----------------------------------|-----------------------------------|
| 按用户ID哈希     | user_id         | “我的订单”“我的优惠券”等用户维度查询 | 数据分布均匀，用户数据集中        | 跨用户查询需遍历多表              |
| 按时间范围       | order_time      | 订单、日志等时间序列数据          | 历史数据归档方便，查询可定位时间表 | 热点集中在最新表（如当月订单表）  |
| 按订单ID范围     | order_id        | 订单ID自增、无用户维度查询        | 扩容简单（新增区间表）            | 热点集中在最新表                  |
| 复合分片（时间+哈希） | order_time + user_id | 高并发订单场景                  | 平衡热点，兼顾时间和用户维度      | 设计复杂                          |

**最佳实践**：订单表优先用**“时间+用户ID哈希”**复合分片（如先按月份分表，再按user_id哈希分库）。


#### 3. 分库分表实现：用中间件简化开发
避免手动在代码中路由表名，优先用成熟中间件：
- **Sharding-JDBC**：客户端中间件（嵌入应用），对代码侵入低，适合Java项目；
- **MyCat/ProxySQL**：服务端中间件（独立部署），支持多语言，适合异构系统；
- **OceanBase/TDSQL**：云原生分布式数据库（自带分库分表能力），适合超大规模业务。

**示例（Sharding-JDBC分库分表配置）**：
```yaml
spring:
  shardingsphere:
    rules:
      sharding:
        tables:
          t_order:  # 逻辑表
            actual-data-nodes: ds_${0..1}.t_order_${202501..202512}_${0..15}  # 分库（ds_0/ds_1）+分表
            database-strategy:  # 分库规则（按user_id哈希）
              standard:
                sharding-column: user_id
                sharding-algorithm-name: user_hash
            table-strategy:  # 分表规则（按时间+user_id哈希）
              complex:
                sharding-columns: order_time,user_id
                sharding-algorithm-name: order_time_user_hash
```


### 三、表设计细节：从字段到索引的极致优化
#### 1. 表结构设计原则
- **字段“轻量化”**：
  - 避免大字段（如TEXT/blob），可拆分到独立表（如订单表不存物流详情，拆到`order_logistics`表）；
  - 用枚举（ENUM）或tinyint代替字符串（如订单状态：0-待支付/1-已支付）；
  - 日期用`datetime`/`timestamp`（4字节）代替字符串，便于范围查询。

- **冷热数据分离**：
  - 热数据（近3个月订单）：保留在核心分表；
  - 冷数据（3个月前订单）：迁移到归档表（如`order_archive_2024`），甚至低成本存储（如S3+ClickHouse）。

#### 2. 索引设计：避免“索引失效”和“过度索引”
- **核心索引必建**：
  - 主键：用**全局唯一ID**（雪花算法/UUID），避免自增ID冲突；
  - 分片键索引：如`user_id`、`order_time`（查询时必须带分片键，否则全表扫描）；
  - 联合索引：按“高频查询字段在前”设计（如`user_id + order_time`）。

- **索引禁忌**：
  - 避免用`*`查询，用**覆盖索引**（SELECT字段包含在索引中，无需回表）；
  - 避免在索引字段做函数操作（如`DATE(order_time) = '2025-01-01'`会失效索引）；
  - 单表索引不超过5个（过多索引会拖慢写入速度）。


### 四、高可用设计：避免单点故障
业务量巨大时，数据库**一旦宕机损失惨重**，需做高可用架构：

#### 1. 数据库集群化
- **MySQL**：采用**MGR（MySQL Group Replication）** 集群（3节点以上），支持自动选主，避免主库单点；
- **分布式数据库**：直接用OceanBase/TDSQL等原生分布式数据库（自带多副本、容灾能力）。

#### 2. 异地多活
超大规模业务需做**“异地多活”**：
- 部署多个地域的数据库集群（如华东+华南）；
- 通过数据同步工具（如DTS）实现跨地域数据复制；
- 结合业务层做流量路由，某地域故障时切换到其他地域。


### 五、关键配套方案
#### 1. 全局ID生成
分库分表后，各表主键需全局唯一：
- **雪花算法（Snowflake）**：64位ID（时间戳+机器ID+序列号），高性能、有序；
- **UUID**：无序，不推荐作为主键（影响索引性能）；
- **数据库自增表**：单独建表（如`sequence_table`）维护全局ID，性能较低，适合小并发。

#### 2. 分布式事务
跨库/跨表事务需保证一致性：
- **强一致性**：用Seata（AT模式）、TCC模式；
- **最终一致性**：用消息队列（如RocketMQ）做异步补偿（如订单创建后异步扣减库存）。

#### 3. 慢查询治理
- 开启MySQL慢查询日志，定期分析（如执行时间>1s的SQL）；
- 避免大事务（如一次性更新10万条数据），拆分为小批量操作；
- 禁用`SELECT *`、`COUNT(*)`（用近似计数或缓存）。


### 六、业务场景示例：电商核心库设计
以电商为例，核心库拆分如下：
1. **用户库（user_db）**：
   - 分库：按user_id哈希分2库；
   - 分表：用户基本表（user_base）+用户扩展表（user_extra）（垂直分表）。

2. **订单库（order_db）**：
   - 分库：按user_id哈希分4库；
   - 分表：按order_time分月表（如order_202501）+user_id哈希分表（共4库×12表=48表）。

3. **商品库（product_db）**：
   - 分表：商品基本表（product_base）+商品库存表（product_stock）；
   - 缓存：商品库存/价格缓存到Redis，避免直接查库。


### 总结
业务量巨大时，数据库设计的核心是**“拆分”+“分流”**：
- 先通过架构分层（缓存、搜索引擎、数据仓库）分流压力；
- 再通过分库分表突破单库单表极限；
- 最后通过高可用设计和细节优化保证稳定性。

核心原则：**“让合适的数据待在合适的存储里”**，避免用MySQL承载所有场景（如全文检索交给ES，统计交给ClickHouse）。