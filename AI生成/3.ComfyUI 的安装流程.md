ComfyUI 的安装流程因操作系统（Windows/macOS/Linux）略有差异，核心分为**环境准备**、**源码下载**、**依赖安装**和**启动运行**四步，以下是详细的分步教程及基础使用指南：


### 一、安装前准备
1. **硬件要求**（参考前文）：需至少 6GB 显存的显卡（NVIDIA 优先，AMD/Intel 核显需额外配置），16GB 内存，SSD 硬盘（预留 50GB+ 空间）。
2. **软件依赖**：
   - **Python**：推荐 3.10.x 版本（3.11 部分依赖可能不兼容），需勾选「Add Python to PATH」；
   - **Git**：用于克隆源码（可选，也可直接下载压缩包）；
   - **显卡驱动**：NVIDIA 安装 CUDA 11.8+，AMD 安装 ROCm（Linux）或最新 Adrenalin 驱动（Windows），macOS 无需额外驱动（M 芯片支持 Metal）。


### 二、Windows 系统安装（最主流）
#### 方法1：一键启动包（新手推荐）
1. 下载官方或社区打包的**一键启动版**（如 [ComfyUI Portable](https://github.com/comfyanonymous/ComfyUI/releases) 或 [秋叶整合包](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-Guide-%E4%B8%AD%E6%96%87#%E7%A7%8B%E5%8F%B6%E6%95%B4%E5%90%88%E5%8C%85)）；
2. 解压到 SSD 目录（避免中文路径）；
3. 运行 `start_windows.bat`，脚本会自动安装依赖并启动，首次启动需等待下载模型和依赖（约 5-10 分钟）。

#### 方法2：手动安装（进阶用户）
1. **克隆源码**：  
   打开命令提示符（CMD），执行：  
   ```bash
   git clone https://github.com/comfyanonymous/ComfyUI.git
   cd ComfyUI
   ```
2. **创建虚拟环境**（可选，避免依赖冲突）：  
   ```bash
   python -m venv venv
   venv\Scripts\activate
   ```
3. **安装依赖**：  
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   pip install -r requirements.txt
   ```
4. **启动 ComfyUI**：  
   ```bash
   python main.py
   ```


### 三、macOS 系统安装（M 芯片优先）
1. 安装 Homebrew（若未安装）：  
   ```bash
   /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
   ```
2. 安装 Python 和 Git：  
   ```bash
   brew install python@3.10 git
   ```
3. 克隆源码并安装依赖：  
   ```bash
   git clone https://github.com/comfyanonymous/ComfyUI.git
   cd ComfyUI
   pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu  # M芯片用Metal加速，无需CUDA
   pip3 install -r requirements.txt
   ```
4. 启动：  
   ```bash
   python3 main.py --force-fp16  # M芯片建议启用FP16加速
   ```


### 四、Linux 系统安装（Ubuntu 为例）
1. 安装系统依赖：  
   ```bash
   sudo apt update && sudo apt install python3.10 python3.10-venv git
   ```
2. 克隆源码并创建虚拟环境：  
   ```bash
   git clone https://github.com/comfyanonymous/ComfyUI.git
   cd ComfyUI
   python3.10 -m venv venv
   source venv/bin/activate
   ```
3. 安装 PyTorch（NVIDIA 显卡）：  
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```
   AMD 显卡需安装 ROCm 后执行：  
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6
   ```
4. 安装其他依赖并启动：  
   ```bash
   pip install -r requirements.txt
   python main.py
   ```


### 五、模型配置
ComfyUI 需下载 Stable Diffusion 模型才能生成图像，步骤如下：
1. 下载模型文件（如 SD1.5、SDXL）：  
   - 推荐来源：[Civitai](https://civitai.com/)、[Hugging Face](https://huggingface.co/models?pipeline_tag=text-to-image&library=stable-diffusion)；
   - 模型格式：`.safetensors`（推荐）或 `.ckpt`。
2. 将模型放入对应目录：  
   - 基础模型：`ComfyUI/models/checkpoints/`；  
   - LoRA 模型：`ComfyUI/models/loras/`；  
   - ControlNet 模型：`ComfyUI/models/controlnet/`；  
   - VAE 模型：`ComfyUI/models/vae/`。


### 六、基础使用指南
#### 1. 启动与访问
- 运行启动脚本后，打开浏览器访问 `http://localhost:8188`（默认端口），进入 ComfyUI 界面。

#### 2. 搭建第一个工作流（文生图）
1. **加载基础节点**：  
   - 拖拽「Load Checkpoint」节点（左侧面板搜索），选择已下载的模型（如 `sd_xl_base_1.0.safetensors`）；  
   - 拖拽「CLIP Text Encode」节点（处理正向提示词）和「CLIP Text Encode (Negative)」节点（处理反向提示词）；  
   - 拖拽「KSampler」节点（采样生成图像）；  
   - 拖拽「VAE Decode」节点（解码 latent 为图像）；  
   - 拖拽「Save Image」节点（保存生成结果）。

2. **连接节点**：  
   - 「Load Checkpoint」的 `MODEL` →「KSampler」的 `MODEL`；  
   - 「Load Checkpoint」的 `CLIP` →「CLIP Text Encode」的 `CLIP`；  
   - 「CLIP Text Encode」的 `CONDITIONING` →「KSampler」的 `POSITIVE`；  
   - 「CLIP Text Encode (Negative)」的 `CONDITIONING` →「KSampler」的 `NEGATIVE`；  
   - 「Load Checkpoint」的 `VAE` →「VAE Decode」的 `VAE`；  
   - 「KSampler」的 `LATENT` →「VAE Decode」的 `LATENT`；  
   - 「VAE Decode」的 `IMAGE` →「Save Image」的 `IMAGE`。

3. **设置参数**：  
   - 在「CLIP Text Encode」的 `text` 框输入正向提示词（如“a beautiful cat, realistic, 8k”）；  
   - 在「CLIP Text Encode (Negative)」的 `text` 框输入反向提示词（如“blurry, low quality, ugly”）；  
   - 「KSampler」中设置采样器（如 `dpmpp_2m`）、步数（`20`）、CFG 缩放（`8`）、图像尺寸（`width=1024, height=1024`）。

4. **执行生成**：  
   点击界面右上角「Queue Prompt」按钮，等待生成完成，结果会保存到 `ComfyUI/output/` 目录。


### 七、常见问题解决
1. **启动失败**：检查 Python 版本（需 3.10）、显卡驱动是否匹配、依赖是否安装完整；  
2. **显存不足**：降低图像分辨率、启用 FP16 模式（启动时加 `--force-fp16`）、使用轻量化模型；  
3. **模型加载失败**：确保模型路径无中文，文件格式为 `.safetensors` 或 `.ckpt`；  
4. **界面卡顿**：关闭其他占用资源的程序，升级显卡驱动。


### 八、进阶扩展
- **安装自定义节点**：克隆第三方节点库到 `ComfyUI/custom_nodes/` 目录，重启 ComfyUI 即可加载；  
- **批量生成**：使用「Loop」节点或「Load Folder」节点实现批量处理；  
- **ControlNet 控制**：添加「Load ControlNet」节点，连接图像输入和控制模型，实现姿态/边缘控制。

通过以上步骤，即可完成 ComfyUI 的安装和基础使用，后续可根据需求探索更复杂的工作流设计！